from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

# Set up Chrome WebDriver
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

# Navigate to the website
driver.get("https://www.example.com")  # Replace with the actual website URL

# Wait for the page to load (optional)
WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))

# Find the elements you want to scrape (replace with your specific selectors)
# Example: Find all links on the page
links = driver.find_elements(By.TAG_NAME, 'a')

# Extract the data you need (replace with your scraping logic)
for link in links:
    href = link.get_attribute('href')
    print(href)

# Close the browser
driver.quit()
